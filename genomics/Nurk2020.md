# Article  
HiCanu: accurate assembly of segmental duplications, satellites, and allelic variants from high-fidelity long reads ([link here](https://doi.org/10.1101/gr.263566.120))  

# Authors  
* Sergey Nurk
* Brian P. Walenz
* Arang Rhie
* Mitchell R. Vollger
* Glennis A. Logsdon
* Robert Grothe
* Karen H. Miga
* Evan E. Eichler
* Adam M. Phillippy
* Sergey Koren

# Journal and Year  
Genome Research (2020)  

# Highlights  
## Advantages of HiFi data  
* Although HiFi reads are shorter (up to 25 Kb) than the traditional CLR reads (that can exceed 50 Kb) or the Nanopore reads (that can exceed 100 Kb), HiFi reads are much more accurate compared to other long-read technologies. While the median accuracy of the former can exceed 99.9% (>Q30), the accuracy of the latter do not exceed 95%. 
## HiCanu vs. Canu  
* HiCanu was built on the original Canu pipeline, which was developed for dealing with conventional long-read data, but it is not optimized to deal with HiFi data. HiCanu was built after replacement and significant modification of Canu's core methods in order to better deal with HiFi data. Here are some key steps in the HiCanu pipeline:  
    1. HiCanu begins by compressing consecutive copies of the same nucleotide (homopolymers) to a single base (e.g. "AA..." becomes "A").  
        * This is done because homopolymer length is the primary error mode of HiFi technology  
    2. The compressed reads are trimmed based on their overlaps to other reads to remove any chimeric sequences or sequencing adapters, and the overlaps are recomputed based on the trimmed reads
    3. The Overlap Error Adjustment (OEA) module examines read overlap pileups to identify remaining sequencing errors in the individual reads and recomputes overlap alignment identities. Here, a modification was applied to the OEA module to ignore any differences within microsatellite repeat arrays due to the fact that they are also prone to HiFi read errors. Then two reads that differ only by an indel detected in a microsatellite region are considered to be 100% identical.   
    <img src="https://user-images.githubusercontent.com/22843614/92035046-826d9480-ed44-11ea-8427-316d65319521.png" width=30%></img>  
    *Figure 1. A) Two hypothetical reads are shown with sequencing errors highlighted in red. B) The first step of HiCanu is to compress homopolymers, which obscures homopolymer length errors but retains enough information to accurately distinguish reads from different genomic loci. C) Overlaps are then computed for the compressed reads, and remaining errors are identified by examining the alignment pileups (gray rectangle). D) Finally, after correcting the identified errors (blue) and ignoring indels in regions of known systematic error (gray), the resulting overlap is 100% identical.*  
    4. The adjusted overlaps are then used to built draft contigs using Canu's Bogart module, modified to better handle heterozygous variants and consider only high-identity read overlaps  
    5. Final contigs are obttained by computing a consensus across the original, uncompressed reads, arranged according to the layout of their compressed versions. 

* Similar to many modern assemblers, when faced with a diploid genome, HiCanu outputs contigs as "pseudo-haplotypes" that preserve local allelic phasing but may switch between haplotypes across longer distances.
    * A single set of contigs representing all resolved alleles is output regardless of ploidy, and **additional processing** with a tool such as **Purge_dups** is required to partition the contigs into primary and alternate allele sets.  

